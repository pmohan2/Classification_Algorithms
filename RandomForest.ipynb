{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapdf(df):\n",
    "    df = df.sample(frac=1, replace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_for_leaf(df,counter, min_samples, max_depth):\n",
    "    unique_classes = np.unique(df)\n",
    "    if len(unique_classes) == 1 or len(df)<=min_samples or counter==max_depth:\n",
    "        labelcol = df\n",
    "        uniq_cls, cnt = np.unique(labelcol, return_counts=True)\n",
    "        classification = unique_classes[cnt.argmax()]\n",
    "        return classification\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_imp_test(df, col_index):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    classes = df.iloc[:,-1]\n",
    "    feature = df.iloc[:,col_index]\n",
    "    if len(feature.unique()) == 2:\n",
    "        gini_imp = 0\n",
    "        for i in np.unique(feature):\n",
    "            idx = np.where(feature == i)\n",
    "            label = classes.loc[idx].values\n",
    "            a, b = np.unique(label, return_counts = True)\n",
    "            list1 = [(i/sum(b))**2 for i in b]\n",
    "            prob = 1 - sum(list1)\n",
    "            wt = len(idx[0]) / df.shape[0]\n",
    "            gini_imp += wt * prob\n",
    "        return gini_imp, i\n",
    "    else:\n",
    "        label = np.sort(feature.unique())[1:-1]\n",
    "        best_gini_imp = float('inf')\n",
    "        split_val = 0\n",
    "        for i in label:\n",
    "            idx1 = np.where(feature > i)\n",
    "            idx2 = np.where(feature <= i)\n",
    "            if len(idx1[0]) > 2 and len(idx2[0]) > 2:\n",
    "        \n",
    "                b1, b1cnt = np.unique(classes.loc[idx1].values, return_counts = True)\n",
    "                b2, b2cnt = np.unique(classes.loc[idx2].values, return_counts = True)\n",
    "                list1 = [(i/sum(b1cnt))**2 for i in b1cnt]\n",
    "                list2 = [(i/sum(b2cnt))**2 for i in b2cnt]\n",
    "                prob1 = 1 - sum(list1)\n",
    "                prob2 = 1 - sum(list2)\n",
    "                gini = ((sum(b1cnt)/df.shape[0])*prob1) + ((sum(b2cnt)/df.shape[0])*prob2) \n",
    "                if gini < best_gini_imp:\n",
    "                    best_gini_imp = gini\n",
    "                    split_val = i\n",
    "                else:\n",
    "                    continue \n",
    "        return best_gini_imp, split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_node(df, col_list):\n",
    "    best_gini_imp = float('inf')\n",
    "    value = 0\n",
    "    col = 0\n",
    "    for i in col_list:\n",
    "        gini, val = gini_imp_test(df, i) \n",
    "        if gini < best_gini_imp:\n",
    "            best_gini_imp = gini\n",
    "            value = val\n",
    "            col = i\n",
    "    return col, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, col_index, split_val):\n",
    "    feature = df.iloc[:,col_index]\n",
    "    if feature.dtypes == object:\n",
    "        temp1 = df[df.iloc[:,col_index] == split_val]\n",
    "        temp2 = df[df.iloc[:,col_index] != split_val]\n",
    "        return temp1, temp2\n",
    "    elif feature.dtypes != object:\n",
    "        temp1 = df[df.iloc[:,col_index] <= split_val]\n",
    "        temp2 = df[df.iloc[:,col_index] >= split_val]\n",
    "        temp1.reset_index(inplace = True, drop = True)\n",
    "        temp2.reset_index(inplace = True, drop = True)\n",
    "        return temp1, temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    return classification\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ts_lb,answer):\n",
    "    TN = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i,j in zip(ts_lb,answer):\n",
    "        if j==1 and i==1:\n",
    "            TP += 1\n",
    "        elif(j==1 and i==0):\n",
    "            FN += 1\n",
    "        elif(j==0 and i==1):\n",
    "            FP += 1\n",
    "        elif(j==0 and i==0):\n",
    "            TN += 1\n",
    "    Accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "    Precision = TP/(TP + FP)\n",
    "    Recall = TP/(TP + FN)\n",
    "    f1_score = (2*Precision*Recall)/(Precision + Recall)\n",
    "    return Accuracy, Precision, Recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(df, columns, num_features, counter = 0, min_samples = 10, max_depth = 5):\n",
    "    if (check_purity(df.values)) or (counter == max_depth) or (len(df) < min_samples):\n",
    "        classification = classify_data(df.values)\n",
    "        \n",
    "        return classification\n",
    "      \n",
    "    else:\n",
    "        counter += 1\n",
    "        col_list = random.sample(columns, num_features)\n",
    "        column, value = best_node(df, col_list)\n",
    "        if df.iloc[:,column].dtype == object:\n",
    "            columns.remove(column)\n",
    "        branch1, branch2 = split_df(df, column, value)\n",
    "        if len(branch1) == 0 or len(branch2) == 0:\n",
    "            classification = classify_data(df.values)\n",
    "            return classification\n",
    "    \n",
    "        query = \"{} <= {}\".format(column, value)\n",
    "        branch = {query: []}\n",
    "\n",
    "        left_branch = decision_tree(branch1, columns, num_features, counter)\n",
    "        right_branch = decision_tree(branch2, columns, num_features, counter)\n",
    "\n",
    "        if left_branch == right_branch:\n",
    "            branch = left_branch\n",
    "        else:\n",
    "            branch[query].append(left_branch)\n",
    "            branch[query].append(right_branch)\n",
    "        return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df, num_trees, num_features):\n",
    "    trees = []\n",
    "    for i in range(num_trees):\n",
    "        df = bootstrapdf(df)\n",
    "        columns = list(df.iloc[:,:-1].columns)\n",
    "        tree = decision_tree(df, columns, num_features)\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    classes = []\n",
    "    for tree in model:\n",
    "        cls = []\n",
    "        for i in range(len(test_data)):\n",
    "            t = tree\n",
    "            col,_,val = list(t.keys())[0].split()\n",
    "            col = int(col)\n",
    "            try:\n",
    "                val = float(val)\n",
    "            except:\n",
    "                val = str(val)\n",
    "            key = list(t.keys())[0]\n",
    "            key_val = t[key]\n",
    "            while True: \n",
    "                if test_data.iloc[i,col] <= val:\n",
    "                    t = t[key][0]\n",
    "                    if type(t) != dict:\n",
    "                        cls.append(t)\n",
    "                        break\n",
    "                    else:\n",
    "                        col,_,val = list(t.keys())[0].split()\n",
    "                        col = int(col)\n",
    "                        try:\n",
    "                            val = float(val)\n",
    "                        except:\n",
    "                            val = str(val)\n",
    "                        key = list(t.keys())[0]\n",
    "                        key_val = t[key]\n",
    "                else:\n",
    "                    t = t[key][1]\n",
    "                    if type(t) != dict:\n",
    "                        cls.append(t)\n",
    "                        break\n",
    "                    else:\n",
    "                        col,_,val = list(t.keys())[0].split()\n",
    "                        col = int(col)\n",
    "                        try:\n",
    "                            val = float(val)\n",
    "                        except:\n",
    "                            val = str(val)\n",
    "                        key = list(t.keys())[0]\n",
    "                        key_val = t[key]\n",
    "        cls = [int(i) for i in cls]\n",
    "        classes.append(cls)\n",
    "    classes = np.array(classes)\n",
    "    final_class = []\n",
    "    for i in range(len(test_data)):\n",
    "        unique_classes, counts_unique_classes = np.unique(classes[:,i], return_counts=True)\n",
    "        index = counts_unique_classes.argmax()\n",
    "        classification = unique_classes[index]\n",
    "        final_class.append(classification)\n",
    "    final_class\n",
    "    test_data[\"Class\"] = final_class\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(df):\n",
    "    num_trees = int(input(\"Enter number of trees: \"))\n",
    "    num_features = int(input(\"Enter number of features for each split: \"))\n",
    "    k = int(input(\"Enter k value: \"))\n",
    "    metrics_list = []\n",
    "    for i in range(k):\n",
    "        splitdfs = np.array_split(df, k)\n",
    "        test = splitdfs[i]\n",
    "        del(splitdfs[i])\n",
    "        train = pd.concat(splitdfs)\n",
    "        test.reset_index(inplace = True, drop = True)\n",
    "        train.reset_index(inplace = True, drop = True) \n",
    "        actual = test.iloc[:,-1]\n",
    "        test = test.iloc[:,:-1]\n",
    "        model = random_forest(train, num_trees, num_features)\n",
    "        results = predict(model, test)\n",
    "        Accuracy, Precision, Recall, f1_score = metrics(actual, results[\"Class\"])\n",
    "        metrics_list.append([Accuracy, Precision, Recall, f1_score])\n",
    "    metrics_list = np.array(metrics_list)\n",
    "    metrics_list = np.mean(metrics_list, axis = 0)\n",
    "    print(\"Accuracy: \",metrics_list[0])\n",
    "    print(\"Precision: \",metrics_list[1])\n",
    "    print(\"Recall: \",metrics_list[2])\n",
    "    print(\"f1_score: \",metrics_list[3])\n",
    "    return metrics_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of trees: 5\n",
      "Enter number of features for each split: 3\n",
      "Enter k value: 10\n",
      "Accuracy:  0.9348997493734335\n",
      "Precision:  0.8793594721240956\n",
      "Recall:  0.9506969696969698\n",
      "f1_score:  0.9120824299912176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.93489975, 0.87935947, 0.95069697, 0.91208243])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"project3_dataset1.txt\", sep = '\\t', header=None)\n",
    "k_fold(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of trees: 5\n",
      "Enter number of features for each split: 3\n",
      "Enter k value: 10\n",
      "Accuracy:  0.6406567992599445\n",
      "Precision:  0.36184248500037974\n",
      "Recall:  0.4885966810966812\n",
      "f1_score:  0.39605076241748566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6406568 , 0.36184249, 0.48859668, 0.39605076])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"project3_dataset2.txt\", sep = '\\t', header=None)\n",
    "k_fold(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
